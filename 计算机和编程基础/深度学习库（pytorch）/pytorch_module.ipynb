{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPDjCVwNaPbhxEZHXzG1zRe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7_I837W6iviG"},"outputs":[],"source":["import torch"]},{"cell_type":"markdown","source":["### 0，Gpu的调用"],"metadata":{"id":"VugbLHZECueY"}},{"cell_type":"code","source":["# 设置设备为 GPU 或 CPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# tensor.to(device):将张量从一个设备移动到另一个设备。device可以是'cuda'（GPU）或'cpu'，也可以指定具体的GPU，如'cuda:0'表示第一个 GPU。\n","# model.to(device):将模型的所有参数转移到指定设备。\n","\n","# 创建一个张量并将其移动到 GPU（如果可用）\n","x = torch.randn(3, 3)\n","x = x.to(device)\n","\n","# 创建模型并将其移动到 GPU（如果可用）\n","model = torch.nn.Linear(3, 3)\n","model = model.to(device)\n","\n"],"metadata":{"id":"uXok25LFC055"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1, torchvision：专门用于计算机视觉任务的拓展库"],"metadata":{"id":"kxGEyxfFjAzB"}},{"cell_type":"markdown","source":["#### （1），图像数据集模块：datasets"],"metadata":{"id":"_jm9Ko5F0xT7"}},{"cell_type":"code","source":["from torchvision import datasets\n","\n","# 1，提供常用的图像分类数据集\n","\n","train_dataset = datasets.FashionMNIST(\n","    root=\"data\", # 在当前目录保存在data文件夹中\n","    train=True,  # 加载训练集数据（False，则加载测试集数据）\n","    download=True, # 下载数据\n","    transform=transform # 加载数据时，将每个图像转换为PyTorch张量\n",")\n","\n","val_dataset = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=transform\n",")\n","\n","# 2，用于从目录结构中加载图像数据集（其中每个文件夹表示一个类别，文件夹中包含该类别的图像文件）\n","\n","# 加载训练数据集\n","train_dataset = datasets.ImageFolder(root='path_to_train_data', transform=transform)\n","# 加载验证数据集\n","val_dataset = datasets.ImageFolder(root='path_to_val_data', transform=transform)"],"metadata":{"id":"7Qcf-910i3cn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### （2），图像变换、预处理模块：transforms"],"metadata":{"id":"Dp1u3jdC021z"}},{"cell_type":"code","source":["from torchvision import transforms\n","\n","# 提供了许多常见的图像变换操作，帮助进行数据预处理\n","\n","transform = transforms.Compose([\n","    transforms.Resize((96, 96)),  # 调整大小为96*96\n","    transforms.RandomCrop((64, 64)),  # 随机裁剪为64*64的区域\n","    transforms.RandomHorizontalFlip(p=0.5),  # 以 50% 的概率随机水平翻转图像\n","    transforms.RandomRotation(45),  # 随机旋转,-45度到45度\n","    transforms.ToTensor(),  # 转换为Tensor\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 标准化\n","])"],"metadata":{"id":"-roZAuJMi3gP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2，utils：工具模块，提供了一些实用工具来帮助处理数据加载、可视化、模型训练、并行化等常见任务"],"metadata":{"id":"MLZ_V0ys0Izf"}},{"cell_type":"markdown","source":["#### （1），数据处理模块：data"],"metadata":{"id":"2imc46mf0sJK"}},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","# 自定义数据集类，用于封装你的数据：Dataset\n","\n","class MyDataset(Dataset):\n","    def __init__(self, data, labels):\n","        self.data = data # 输入数据，比如图像\n","        self.labels = labels\n","\n","    def __len__(self):\n","        \"\"\"返回数据集的大小\"\"\"\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"根据索引返回一个样本\"\"\"\n","        data = self.data[idx]\n","        label = self.labels[idx]\n","        return data, label\n","\n","\n","from torch.utils.data import DataLoader\n","# 批量加载数据，并支持多线程加载、数据打乱等功能，与Dataset配合使用：DataLoader\n","\n","# 创建 DataLoader 对象\n","train_dataset = MNISTDataset(X_train, y_train, transform=transform)\n","val_dataset = MNISTDataset(X_val, y_val, transform=transform)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True) # shuffle参数:是否在每个epoch后打乱数据\n","val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","\n","\n","from torch.utils.data import Subset\n","from sklearn.model_selection import train_test_split\n","# 从一个现有的数据集中提取一个子集，通常配合索引使用（可以用于划分图像文件训练集和测试集）\n","\n","full_dataset = datasets.ImageFolder(root='data/train', transform=transform)\n","\n","# 划分训练集和验证集的索引\n","indices = list(range(len(full_dataset)))\n","train_indices, val_indices = train_test_split(indices, test_size=0.2, random_state=42)\n","\n","train_dataset = Subset(full_dataset, train_indices)\n","val_dataset = Subset(full_dataset, val_indices)\n"],"metadata":{"id":"by2hPekyi3jp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### （2），可视化模块：tensorboard"],"metadata":{"id":"qR9H7lWWA9eZ"}},{"cell_type":"code","source":["from torch.utils.tensorboard import SummaryWriter\n","# 见tensorboard专题文件"],"metadata":{"id":"Zw4Ma66WA8lC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3，nn模块：构建和训练神经网络的核心部分。它提供了许多用于定义神经网络层、损失函数等的工具"],"metadata":{"id":"c_LjvO2k4gnd"}},{"cell_type":"markdown","source":["#### （1），神经网络层（Layers）"],"metadata":{"id":"FqsgLFJU5xKJ"}},{"cell_type":"code","source":["from torch import nn\n","\n","layer = nn.Linear(in_features=10, out_features=5) # 线性层 （全连接层） # flatten = nn.Flatten()将高维张量展平为二维张量，用于将卷积层的输出传递给全连接层。\n","\n","conv = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=2, padding=1)# 2d卷积层 （参数：表示3个输入通道（如RGB图像），输出16个通道，卷积核大小为3x3，步长和填充）\n","\n","pool = nn.MaxPool2d(kernel_size=2, stride=2) # 2d最大池化层 （参数：表示使用2x2的窗口进行池化操作，步长为2） （nn.AvgPool1d：1d平均池化层，d表示维度）\n","\n","bn = nn.BatchNorm2d(num_features=16) # 2d批量归一化层 （参数：指定了输入张量中的通道数）\n","\n","rnn = nn.RNN(input_size=10, hidden_size=20, num_layers=2) # 循环神经网络层\n","\n","lstm = nn.LSTM(input_size=10, hidden_size=20, num_layers=2) # 长短期记忆（LSTM）层\n","\n","gru = nn.GRU(input_size=10, hidden_size=20, num_layers=2) # 门控循环单元（GRU）层\n","\n","embedding = nn.Embedding(num_embeddings=1000, embedding_dim=128) # 嵌入层 （参数：词汇表大小，每个词汇嵌入向量的维度）\n","\n","attention = nn.MultiheadAttention(embed_dim=256, num_heads=8) # 多头自注意力层\n","\n","dropout = nn.Dropout(p=0.5) # Dropout层，用于随机丢弃神经网络中的部分神经元，以减少过拟合。\n"],"metadata":{"id":"xYsB3YSV5wLv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### （2），激活函数（Activation Functions）"],"metadata":{"id":"Rt3SUOSG5wkv"}},{"cell_type":"code","source":["from torch import nn\n","\n","relu = nn.ReLU()\n","\n","sigmoid = nn.Sigmoid()\n","\n","softmax = nn.Softmax()\n","\n","tanh = nn.Tanh()\n","\n","prelu = nn.PReLU()\n"],"metadata":{"id":"XHnP7gLf4v7s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### （3），损失函数（Loss Functions）"],"metadata":{"id":"nytODKZV6Eht"}},{"cell_type":"code","source":["from torch import nn\n","\n","mse_loss = nn.MSELoss() # 均方误差损失函数\n","\n","cross_entropy_loss = nn.CrossEntropyLoss() # 交叉熵损失函数"],"metadata":{"id":"Uj5oh0WH6Ewl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### （4），模块（module）"],"metadata":{"id":"cbLHo54S6FJA"}},{"cell_type":"code","source":["from torch import nn\n","\"\"\"\n","nn.Module 是所有神经网络模块的基类。所有的神经网络层（如 nn.Linear）都是从 nn.Module 继承的。\n","要创建一个自定义的神经网络模型，通常会继承 nn.Module 并重写 __init__ 和 forward 方法。\n","\"\"\"\n","class MyModule(nn.Module):\n","    def __init__(self):\n","        super().__init__() # 初始化继承自父类的属性\n","        # 卷积层 1\n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n","        self.relu1 = nn.ReLU()\n","        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        # 卷积层 2\n","        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n","        self.relu2 = nn.ReLU()\n","        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        # 展平层：将多维输入展平为一维\n","        self.flatten = nn.Flatten()\n","\n","        # 全连接层\n","        self.linear1 = nn.Linear(64 * 7 * 7, 128)  # 64个7x7的特征图\n","        self.linear2 = nn.Linear(128, 10)  # 输出10类，对应与自己的分类任务有多少类\n","\n","        # 输出层不加激活函数，损失函数CrossEntropyLoss会自动应用softmax\n","\n","    def forward(self, x):\n","        # 卷积层 1\n","        x = self.pool1(self.relu1(self.conv1(x)))\n","\n","        # 卷积层 2\n","        x = self.pool2(self.relu2(self.conv2(x)))\n","\n","        # 全连接层\n","        x = self.relu1(self.linear1(self.flatten(x)))\n","\n","        # 输出层\n","        x = self.linear2(x)\n","\n","        return x"],"metadata":{"id":"szzTk7xP6FWv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4，optim模块：优化模块，提供了多种常用的优化算法，用于更新模型的参数以最小化损失函数"],"metadata":{"id":"L6mUVh5l6Fkk"}},{"cell_type":"code","source":["from torch import optim\n","\n","optimizer = optim.SGD(model.parameters(), lr=0.01) # SGD随机梯度下降\n","\n","optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4) # Adam自适应调整每个参数的学习率，L2正则化\n","\n","optimizer.zero_grad()  # 清空梯度\n","\n","optimizer.step()  # 更新模型参数\n"],"metadata":{"id":"-IFRkFEd6Fy9","colab":{"base_uri":"https://localhost:8080/","height":217},"executionInfo":{"status":"error","timestamp":1733897596095,"user_tz":-480,"elapsed":4512,"user":{"displayName":"YANGSHEN YU","userId":"05751253873803936475"}},"outputId":"288bbd89-e7c0-4724-dc72-a7c1bf61e6e9"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'model' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d96e13b6cfec>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# SGD随机梯度下降\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Adam自适应调整每个参数的学习率，L2正则化\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"markdown","source":["### 5，autograd模块：用于自动求导（自动计算梯度）的核心模块"],"metadata":{"id":"7gh6p6nUpDt4"}},{"cell_type":"code","source":["# 不需要显式地导入。因为autograd是PyTorch中的内置功能，torch模块已经自动包含了autograd\n","\n","loss.backward() # 反向传播\n","\n","with torch.no_grad(): # 禁用自动求导\n","\n","print(x.grad) # 打印x的梯度\n"],"metadata":{"id":"klaWGtRKpCmq"},"execution_count":null,"outputs":[]}]}