{"cells":[{"cell_type":"markdown","metadata":{"id":"L_vQ5oZW2e2S"},"source":["## 一，张量"]},{"cell_type":"markdown","metadata":{"id":"oRCMK3--6VGU"},"source":["### 1,张量的初始化"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":617,"status":"ok","timestamp":1731328844983,"user":{"displayName":"YANGSHEN YU","userId":"05751253873803936475"},"user_tz":-480},"id":"UaFh6YHgyYpd","outputId":"268b6780-0b26-4d57-b7f4-aa11a49b5319"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1, 2],\n","        [3, 4]])\n","tensor([[1, 2],\n","        [3, 4]])\n","t: tensor([1., 1., 1., 1., 1.])\n","n: [1. 1. 1. 1. 1.]\n","tensor([[1, 1],\n","        [1, 1]])\n","tensor([[0.4512, 0.0147],\n","        [0.6162, 0.4524]])\n","tensor([[0, 0],\n","        [0, 0]])\n","tensor([[0.8626, 0.2893, 0.8637],\n","        [0.2028, 0.4192, 0.3593]])\n","tensor([[1., 1., 1.],\n","        [1., 1., 1.]])\n","tensor([[0., 0., 0.],\n","        [0., 0., 0.]])\n"]}],"source":["import torch\n","import numpy as np\n","\n","# 直接从数据创建张量\n","data = [[1,2], [3,4]]\n","x_data = torch.tensor(data)\n","print(x_data)\n","\n","# 从numpy数组创建张量\n","np_array = np.array(data)\n","x_np = torch.from_numpy(np_array)\n","print(x_np)\n","\n","# 张量转numpy数组\n","t = torch.ones(5)\n","print(f\"t: {t}\")\n","n = t.numpy()\n","print(f\"n: {n}\")\n","\n","# 从另一个张量获取形状和数据类型\n","x_ones = torch.ones_like(x_data) # 用1填充\n","print(x_ones)\n","\n","x_rand = torch.rand_like(x_data, dtype=torch.float) # 用（0,1）之间的随机数填充\n","print(x_rand) # dtype指定张量的数据类型\n","\n","x_zeros = torch.zeros_like(x_data) # 用0填充\n","print(x_zeros)\n","\n","# 使用随机或恒定值\n","shape = (2, 3) # shape元组指定张量的形状\n","rand = torch.rand(shape)\n","ones = torch.ones(shape)\n","zeros = torch.zeros(shape)\n","print(rand)\n","print(ones)\n","print(zeros)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"pVZu-ozdCPAO"},"source":[]},{"cell_type":"markdown","metadata":{"id":"Zo-5XL_R6dDI"},"source":["### 2，张量的属性"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":404,"status":"ok","timestamp":1731290283769,"user":{"displayName":"YANGSHEN YU","userId":"05751253873803936475"},"user_tz":-480},"id":"X4ORDA-16j-f","outputId":"0eeb6ef3-c1a1-461e-9a64-a8aa3a6be45f"},"outputs":[{"name":"stdout","output_type":"stream","text":["张量的形状：torch.Size([3, 4])\n","张量的数据类型：torch.float32\n","张量的储存位置：cpu\n"]}],"source":["import torch\n","tensor = torch.rand(3,4)\n","print(f\"张量的形状：{tensor.shape}\")\n","print(f\"张量的数据类型：{tensor.dtype}\")\n","print(f\"张量的储存位置：{tensor.device}\")"]},{"cell_type":"markdown","metadata":{"id":"1OH8bTY28a7N"},"source":["### 3,张量上的计算"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":619,"status":"ok","timestamp":1731328706034,"user":{"displayName":"YANGSHEN YU","userId":"05751253873803936475"},"user_tz":-480},"id":"_Shq1OKV8lbN","outputId":"fcd71a6f-e78a-4fa4-8afb-c109229ff0ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n","tensor([[0.8246, 0.0961, 0.3897, 0.1959],\n","        [0.6606, 0.3452, 0.3330, 0.7528],\n","        [0.1430, 0.7749, 0.7842, 0.7291],\n","        [0.9092, 0.9437, 0.2318, 0.0619]], device='cuda:0')\n","tensor(0.0961, device='cuda:0')\n","tensor([0.8246, 0.0961, 0.3897, 0.1959], device='cuda:0')\n","tensor([0.8246, 0.6606, 0.1430, 0.9092], device='cuda:0')\n","tensor([[0.8246, 0.0961, 0.3897, 0.0000],\n","        [0.6606, 0.3452, 0.3330, 0.0000],\n","        [0.1430, 0.7749, 0.7842, 0.0000],\n","        [0.9092, 0.9437, 0.2318, 0.0000]], device='cuda:0')\n","tensor([[0.8246, 0.0961, 0.3897, 0.0000, 0.8246, 0.0961, 0.3897, 0.0000],\n","        [0.6606, 0.3452, 0.3330, 0.0000, 0.6606, 0.3452, 0.3330, 0.0000],\n","        [0.1430, 0.7749, 0.7842, 0.0000, 0.1430, 0.7749, 0.7842, 0.0000],\n","        [0.9092, 0.9437, 0.2318, 0.0000, 0.9092, 0.9437, 0.2318, 0.0000]],\n","       device='cuda:0')\n","tensor([[0.8246, 0.0961, 0.3897, 0.0000],\n","        [0.6606, 0.3452, 0.3330, 0.0000],\n","        [0.1430, 0.7749, 0.7842, 0.0000],\n","        [0.9092, 0.9437, 0.2318, 0.0000],\n","        [0.8246, 0.0961, 0.3897, 0.0000],\n","        [0.6606, 0.3452, 0.3330, 0.0000],\n","        [0.1430, 0.7749, 0.7842, 0.0000],\n","        [0.9092, 0.9437, 0.2318, 0.0000]], device='cuda:0')\n","tensor([[0.8411, 0.7077, 0.4980, 0.9307],\n","        [0.7077, 0.6664, 0.6230, 1.0036],\n","        [0.4980, 0.6230, 1.2358, 1.0430],\n","        [0.9307, 1.0036, 1.0430, 1.7709]], device='cuda:0')\n","tensor([[0.8411, 0.7077, 0.4980, 0.9307],\n","        [0.7077, 0.6664, 0.6230, 1.0036],\n","        [0.4980, 0.6230, 1.2358, 1.0430],\n","        [0.9307, 1.0036, 1.0430, 1.7709]], device='cuda:0')\n","tensor([[0.8411, 0.7077, 0.4980, 0.9307],\n","        [0.7077, 0.6664, 0.6230, 1.0036],\n","        [0.4980, 0.6230, 1.2358, 1.0430],\n","        [0.9307, 1.0036, 1.0430, 1.7709]], device='cuda:0')\n","tensor([[0.6800, 0.0635, 0.0557, 0.0000],\n","        [0.0635, 0.1192, 0.2580, 0.0000],\n","        [0.0557, 0.2580, 0.6150, 0.0000],\n","        [0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0')\n","tensor([[0.6800, 0.0635, 0.0557, 0.0000],\n","        [0.0635, 0.1192, 0.2580, 0.0000],\n","        [0.0557, 0.2580, 0.6150, 0.0000],\n","        [0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0')\n","tensor([[0.6800, 0.0635, 0.0557, 0.0000],\n","        [0.0635, 0.1192, 0.2580, 0.0000],\n","        [0.0557, 0.2580, 0.6150, 0.0000],\n","        [0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0')\n","6.435909271240234 <class 'float'>\n"]}],"source":["import torch\n","\n","tensor = torch.rand(4,4)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # 如果电脑存在Gpu将张量移动到Gpu上\n","tensor.to(device)\n","print(tensor.device) #输出cude：0代表第一个Gpu\n","print(tensor)\n","\n","print(tensor[0, 1]) #[指定行，指定列]\n","print(tensor[0]) # 打印张量第一行\n","print(tensor[:, 0]) # 打印张量第一列\n","tensor[..., -1] = 0 # ...是一个省略符号，表示选择所有维度\n","print(tensor)\n","\n","# torch.cat() 是 PyTorch 中用于连接张量的函数。它可以沿指定的维度（dim）将多个张量连接起来。\n","t1 = torch.cat([tensor, tensor], dim=1) #按列拼接\n","print(t1)\n","t2 = torch.cat([tensor, tensor], dim=0) #按行拼接\n","print(t2)\n","\n","# 这段代码计算了两个张量之间的矩阵乘法。y1、y2、y3 的值是相同的\n","# ``tensor.T`` 返回张量的转置\n","y1 = tensor @ tensor.T\n","y2 = tensor.matmul(tensor.T)\n","\n","y3 = torch.rand_like(y1)\n","torch.matmul(tensor, tensor.T, out=y3)\n","print(y1)\n","print(y2)\n","print(y3)\n","\n","# 这段代码计算了逐元素的乘积。z1、z2、z3 的值是相同的\n","z1 = tensor * tensor.T\n","z2 = tensor.mul(tensor.T)\n","z3 = torch.rand_like(z1)\n","torch.mul(tensor, tensor.T, out=z3)\n","print(z1)\n","print(z2)\n","print(z3)\n","\n","agg = tensor.sum() # tensor.sum() 会把张量中的所有元素相加，返回一个标量张量（也就是只有一个元素的张量）\n","agg_item = agg.item() #agg.item()：这个方法用于从只有一个元素的张量（标量张量）中提取出该元素的值，并返回 Python 标量类型\n","print(agg_item, type(agg_item))"]},{"cell_type":"markdown","metadata":{"id":"QwCozP-bo_aY"},"source":["## 二，数据集和数据加载"]},{"cell_type":"markdown","metadata":{"id":"3qmWx93lpG6m"},"source":["### 1，加载数据集"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":843},"executionInfo":{"elapsed":6905,"status":"ok","timestamp":1731380197439,"user":{"displayName":"YANGSHEN YU","userId":"05751253873803936475"},"user_tz":-480},"id":"-8hGDQ_CpimN","outputId":"aab01822-5064-41b7-ec90-374a40ed4448"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 26421880/26421880 [00:02<00:00, 13168531.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 29515/29515 [00:00<00:00, 212028.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4422102/4422102 [00:01<00:00, 3864606.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5148/5148 [00:00<00:00, 6354407.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n","\n","批次特征的形状: torch.Size([64, 1, 28, 28])\n","批次标签的形状: torch.Size([64])\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Label: 4\n"]}],"source":["import torch\n","from torchvision import datasets # 用于加载常见的数据集\n","from torchvision.transforms import ToTensor # 图像预处理的转换方法，将图像转换为 PyTorch 张量\n","from torch.utils.data import DataLoader # 用于批量加载数据，自动将数据划分为小批次，支持多线程加载、数据打乱等功能。\n","import matplotlib.pyplot as plt\n","\n","training_data = datasets.FashionMNIST(\n","    root=\"data\", # 在当前目录保存在data文件夹中\n","    train=True,  # 加载训练集数据（False，则加载测试集数据）\n","    download=True, # 下载数据\n","    transform=ToTensor() # 加载数据时，将每个图像转换为PyTorch张量\n",")\n","\n","test_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=ToTensor()\n",")\n","\n","train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True) # 每次加载 64 张图片\n","test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True) # 每个epoch结束后，数据会被打乱（有助于提高模型的泛化能力）\n","\n","train_features, train_labels = next(iter(train_dataloader)) # iter()返回一个迭代器，next()获取一个批次的数据\n","print(f\"批次特征的形状: {train_features.size()}\") # 64：批次大小 1：每张图只有一个颜色通道（灰度图） 28：图像高度 28：图像宽度\n","print(f\"批次标签的形状: {train_labels.size()}\")\n","img = train_features[0].squeeze()  # squeeze()移除所有大小为1的维度\n","label = train_labels[0]\n","plt.imshow(img, cmap=\"gray\") # 使用matplotlib显示图像。cmap=\"gray\"表示使用灰度色图来显示图像。\n","plt.show()\n","print(f\"Label: {label}\") # 打印出该图像的标签（即对应的数字标签）\n","\n","# 0: T恤\n","# 1: 裤子\n","# 2: 套头衫\n","# 3: 连衣裙\n","# 4: 外套\n","# 5: 凉鞋\n","# 6: 衬衫\n","# 7: 运动鞋\n","# 8: 包\n","# 9: 脚踝靴"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aA8ClAvbSxrX"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"wUP64FTgPZkL"},"source":["### 2， 创建自定义的数据集"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0xlHRK5awDkC"},"outputs":[],"source":["import os\n","from torch.utils.data import Dataset\n","from torchvision.io import read_image\n","import pandas as pd\n","from torch.utils.data import DataLoader\n","\n","class MyDataset(Dataset):\n","    def __init__(self, img_labels, img_dir, transform, target_transform):\n","        self.img_labels = pd.read_csv(img_labels)\n","        self.img_dir = img_dir\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","    def __len__(self):\n","        return len(self.img_labels)\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n","        image = read_image(img_path)\n","        label = self.img_labels.iloc[idx, 1]\n","        if self.transform:\n","            image = self.transform(image)\n","        if self.target_transform:\n","            label = self.target_transform(label)\n","        return image, label\n"]},{"cell_type":"markdown","metadata":{"id":"MgTv_KF1bclI"},"source":["### 3，合并"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":484},"executionInfo":{"elapsed":3267,"status":"ok","timestamp":1731466604690,"user":{"displayName":"YANGSHEN YU","userId":"05751253873803936475"},"user_tz":-480},"id":"pVxe9jPHbhdJ","outputId":"54297161-33cc-4964-aacd-806c11fd6250"},"outputs":[{"name":"stdout","output_type":"stream","text":["批次特征的形状: torch.Size([64, 1, 28, 28])\n","批次标签的形状: torch.Size([64])\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Label: 3\n"]}],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms  # transforms提供了多个常用的图像转换操作，可以在数据加载过程中对图像进行变换（如调整大小、裁剪、标准化等）\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","\n","\n","\n","# 加载训练数据\n","train_data = pd.read_csv('/content/drive/MyDrive/kaggle/digit/train.csv')\n","\n","\n","# 训练数据有一个目标列 'label'，其余的列是像素值\n","X = train_data.drop('label', axis=1).values  # 图像的像素数据\n","y = train_data['label'].values  # 标签（0-9数字）\n","\n","# 将图像数据标准化到[0, 1]之间\n","X = X / 255.0\n","\n","# 将数据重新排列成28x28的形状\n","X = X.reshape(-1, 28, 28, 1)  # 28x28的单通道图像\n","\n","# 分割为训练集和验证集\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# 将数据转换为 PyTorch 的 Dataset 格式\n","class MNISTDataset(Dataset):\n","    def __init__(self, images, labels, transform=None):\n","        self.images = images # images:一个包含所有图像数据的数组或张量，通常是形状为(N, 28, 28, 1)，每张图像是一个28x28的单通道灰度图\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx): # 负责通过索引返回一个图像和其对应的标签\n","        image = self.images[idx]\n","        label = self.labels[idx]\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, label\n","\n","# 定义数据增强和转换\n","# transforms.Compose用于将多个变换操作按顺序组合成一个复合变换。它会依次应用所有的变换，从而使图像在被加载时依次经过这些处理\n","transform = transforms.Compose([\n","    transforms.ToTensor(),  # 转换为Tensor类型\n","    transforms.Normalize(mean=[0.5], std=[0.5])  # 对图像进行标准化处理\n","])\n","\n","# 创建 Dataset 和 DataLoader\n","train_dataset = MNISTDataset(X_train, y_train, transform=transform)\n","test_dataset = MNISTDataset(X_val, y_val, transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","train_features, train_labels = next(iter(train_loader)) # iter()返回一个迭代器，next()获取一个批次的数据\n","print(f\"批次特征的形状: {train_features.size()}\") # 64：批次大小 1：每张图只有一个颜色通道（灰度图） 28：图像高度 28：图像宽度\n","print(f\"批次标签的形状: {train_labels.size()}\")\n","\n","img = train_features[0].squeeze()\n","label = train_labels[0]\n","plt.imshow(img, cmap=\"gray\")\n","plt.show()\n","print(f\"Label: {label}\")\n"]},{"cell_type":"markdown","metadata":{"id":"lCl7XQcLdD7F"},"source":["## 三，构建神经网络"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i4xWSlA6dI8I"},"outputs":[],"source":["import os\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms"]},{"cell_type":"markdown","metadata":{"id":"LGt_cflHhT0b"},"source":["### 1，获取训练设备"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1731487960181,"user":{"displayName":"YANGSHEN YU","userId":"05751253873803936475"},"user_tz":-480},"id":"QxBHkg1R6R3j","outputId":"ce1e0343-fb90-49be-c5e7-f6fc2b29ac42"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cpu device\n"]}],"source":["device = (\n","    \"cuda\"\n","    if torch.cuda.is_available()\n","    else \"mps\"\n","    if torch.backends.mps.is_available()\n","    else \"cpu\"\n",")\n","print(f\"Using {device} device\")"]},{"cell_type":"markdown","metadata":{"id":"MQ_1o0pxhejV"},"source":["### 2，定义类"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":588,"status":"ok","timestamp":1731488732827,"user":{"displayName":"YANGSHEN YU","userId":"05751253873803936475"},"user_tz":-480},"id":"Zc-2HDxDhRRE","outputId":"1b8bba6a-6da9-49be-ee00-4f2eb3f0cb45"},"outputs":[{"name":"stdout","output_type":"stream","text":["NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n","层: linear_relu_stack.0.weight | 形状: torch.Size([512, 784]) | 值 : tensor([[ 0.0185,  0.0301, -0.0356,  ...,  0.0026,  0.0288,  0.0303],\n","        [ 0.0269, -0.0277,  0.0322,  ..., -0.0213, -0.0174, -0.0094]],\n","       grad_fn=<SliceBackward0>) \n","\n","层: linear_relu_stack.0.bias | 形状: torch.Size([512]) | 值 : tensor([-0.0344, -0.0308], grad_fn=<SliceBackward0>) \n","\n","层: linear_relu_stack.2.weight | 形状: torch.Size([512, 512]) | 值 : tensor([[ 0.0160, -0.0227, -0.0018,  ..., -0.0152, -0.0422,  0.0043],\n","        [ 0.0409,  0.0220,  0.0425,  ...,  0.0109,  0.0209,  0.0253]],\n","       grad_fn=<SliceBackward0>) \n","\n","层: linear_relu_stack.2.bias | 形状: torch.Size([512]) | 值 : tensor([-0.0177,  0.0435], grad_fn=<SliceBackward0>) \n","\n","层: linear_relu_stack.4.weight | 形状: torch.Size([10, 512]) | 值 : tensor([[ 0.0311, -0.0225, -0.0096,  ...,  0.0368, -0.0071, -0.0022],\n","        [ 0.0167,  0.0051, -0.0091,  ..., -0.0275, -0.0108,  0.0202]],\n","       grad_fn=<SliceBackward0>) \n","\n","层: linear_relu_stack.4.bias | 形状: torch.Size([10]) | 值 : tensor([-0.0004,  0.0256], grad_fn=<SliceBackward0>) \n","\n"]}],"source":["class NeuralNetwork(nn.Module): # torch.nn.Module是PyTorch中所有神经网络模块的基类，你的模型需要继承这个类\n","    def __init__(self):\n","        super().__init__() # 这行代码调用了父类（nn.Module）的构造函数，以便正确初始化\n","\n","        self.flatten = nn.Flatten() # 将输入张量展平的层。它将输入的多维张量（如28x28的图像）转换成一维向量（比如28*28=784维）\n","\n","        # nn.Sequential 是一个顺序容器，用来按顺序将多个层组合在一起\n","        # nn.Linear(in_features, out_features)是PyTorch中定义全连接层的方法。它会创建一个有in_features个输入和out_features个输出的线性变换\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512), # 全连接层，输入大小为28x28=784（每张图像展平后的大小），输出大小为512。\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10),\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x) # 将输入图像展平成一维向量\n","        logits = self.linear_relu_stack(x) # 通过神经网络进行前向传播\n","        return logits\n","\n","    def pred(self, logits):\n","        pred_probab = nn.Softmax(dim=1)(logits) # 对类别维度使用Softmax转化为概率\n","        y_pred = pred_probab.argmax(1) # 获取概率最大的类别索引\n","        return y_pred\n","\n","# 创建一个实例\n","model = NeuralNetwork().to(device) # to(device)是PyTorch的一个方法，用于将模型或者张量移动到指定的训练设备上\n","print(model)\n","\n","\n","# named_parameters()返回一个生成器，每次迭代返回一个元组，包含：\n","# name:层的名称（即参数所在层的名称）\n","# param:参数本身（通常是一个张量）\n","\n","for name, param in model.named_parameters():\n","    print(f\"层: {name} | 形状: {param.size()} | 值: {param[:2]} \\n\")\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"52AxPtZBzDBG"},"source":["## 四，自动微分"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1019,"status":"ok","timestamp":1731507671760,"user":{"displayName":"YANGSHEN YU","userId":"05751253873803936475"},"user_tz":-480},"id":"aIfhsShCzRKr","outputId":"cd14b422-d2c6-415f-dd3e-14d80ff9d4ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["Gradient function for z = <AddBackward0 object at 0x7d24b046f070>\n","Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x7d24b01afa30>\n","tensor([[0.3296, 0.0389, 0.1336],\n","        [0.3296, 0.0389, 0.1336],\n","        [0.3296, 0.0389, 0.1336],\n","        [0.3296, 0.0389, 0.1336],\n","        [0.3296, 0.0389, 0.1336]])\n","tensor([0.3296, 0.0389, 0.1336])\n","True\n","False\n"]}],"source":["import torch\n","\n","x = torch.ones(5)  # input tensor\n","y = torch.zeros(3)  # expected output\n","w = torch.randn(5, 3, requires_grad=True) # requires_grad=True表示我们希望在计算梯度时，PyTorch 会自动跟踪这个张量的梯度\n","b = torch.randn(3, requires_grad=True)\n","z = torch.matmul(x, w)+b\n","loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y) # binary_cross_entropy_with_logits 函数用于计算二分类问题的交叉熵损失\n","\n","print(f\"Gradient function for z = {z.grad_fn}\") # z.grad_fn显示了张量z是如何通过计算图生成的，它指向生成z张量的操作（如矩阵乘法和加法）。\n","print(f\"Gradient function for loss = {loss.grad_fn}\") # loss.grad_fn显示了loss张量是通过二分类交叉熵损失函数生成的\n","\n","loss.backward() # 调用loss.backward()触发反向传播\n","print(w.grad) # w.grad存储的是权重w的梯度。这个梯度表示了损失函数关于权重w的导数。\n","print(b.grad) # b.grad存储的是偏置b的梯度。这个梯度表示了损失函数关于偏置项b的导数。\n","\n","# 梯度的禁用\n","z = torch.matmul(x, w)+b\n","print(z.requires_grad)\n","\n","with torch.no_grad(): #torch.no_grad()是一个上下文管理器，用于在其中的代码块中临时禁用自动求导\n","    z = torch.matmul(x, w)+b\n","print(z.requires_grad)"]},{"cell_type":"markdown","metadata":{"id":"mWKf_iyP-55z"},"source":["## 五，优化模型参数"]},{"cell_type":"markdown","metadata":{"id":"ew9omsZZ_yhm"},"source":["### 1，先决条件"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14350,"status":"ok","timestamp":1731569848067,"user":{"displayName":"YANGSHEN YU","userId":"05751253873803936475"},"user_tz":-480},"id":"Q_p3ZesY-9cu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6bca006d-1873-44db-d69e-120f84403846"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 26.4M/26.4M [00:02<00:00, 11.6MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 29.5k/29.5k [00:00<00:00, 208kB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4.42M/4.42M [00:01<00:00, 3.90MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.15k/5.15k [00:00<00:00, 6.03MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","\n","training_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor()\n",")\n","\n","test_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=ToTensor()\n",")\n","\n","train_dataloader = DataLoader(training_data, batch_size=64)\n","test_dataloader = DataLoader(test_data, batch_size=64)\n","\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10),\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","\n","model = NeuralNetwork()\n"]},{"cell_type":"markdown","metadata":{"id":"7E0y_PP2_Ofn"},"source":["### 2，补充：超参数介绍"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fUYfPA6ZAFgG"},"outputs":[],"source":["# learning_rate = 1e-3    学习率- 每次批次/时期更新模型参数的程度。较小的值会导致学习速度变慢，而较大的值可能会导致训练期间出现不可预测的行为。\n","# batch_size = 64    批次大小- 参数更新之前通过网络传播的数据样本数量\n","# epochs = 5    迭代次数——对数据集进行迭代的次数"]},{"cell_type":"markdown","metadata":{"id":"1g8sF8BeAKEA"},"source":["### 3， 损失函数"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UWKWPAA7AQB4"},"outputs":[],"source":["# 交叉熵损失函数\n","loss_fn = nn.CrossEntropyLoss()"]},{"cell_type":"markdown","metadata":{"id":"Z37-A8cLBFTF"},"source":["### 4， 优化器"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":217},"executionInfo":{"elapsed":6,"status":"error","timestamp":1731511841147,"user":{"displayName":"YANGSHEN YU","userId":"05751253873803936475"},"user_tz":-480},"id":"n9sv6kGhBHYC","outputId":"35ed5559-bcf7-4fc8-ef95-599d6499bd44"},"outputs":[{"ename":"NameError","evalue":"name 'learning_rate' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-9554537c158b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 随机梯度下降SGD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# params需要优化的参数（通常是模型的参数）。一般情况下，我们会传入模型的parameters()。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# lr (learning_rate)设置学习率\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'learning_rate' is not defined"]}],"source":["# 随机梯度下降SGD\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","# params需要优化的参数（通常是模型的参数）。一般情况下，我们会传入模型的parameters()。\n","# lr (learning_rate)设置学习率"]},{"cell_type":"markdown","metadata":{"id":"ixvnktokCDGS"},"source":["### 5， 全面实施"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M1MyrWZ0CFco","executionInfo":{"status":"ok","timestamp":1731570227435,"user_tz":-480,"elapsed":379371,"user":{"displayName":"YANGSHEN YU","userId":"05751253873803936475"}},"outputId":"a59e5797-a8f6-4b75-d9d5-4a6c186dc09e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","-------------------------------\n","loss: 2.300536  [   64/60000]\n","loss: 2.168556  [ 6464/60000]\n","loss: 1.822273  [12864/60000]\n","loss: 1.528330  [19264/60000]\n","loss: 1.175690  [25664/60000]\n","loss: 1.075657  [32064/60000]\n","loss: 1.019092  [38464/60000]\n","loss: 0.887709  [44864/60000]\n","loss: 0.870809  [51264/60000]\n","loss: 0.804686  [57664/60000]\n","Test Error: \n"," Accuracy: 71.0%, Avg loss: 0.794373 \n","\n","Epoch 2\n","-------------------------------\n","loss: 0.794880  [   64/60000]\n","loss: 0.849585  [ 6464/60000]\n","loss: 0.600868  [12864/60000]\n","loss: 0.778405  [19264/60000]\n","loss: 0.659681  [25664/60000]\n","loss: 0.648631  [32064/60000]\n","loss: 0.718417  [38464/60000]\n","loss: 0.693720  [44864/60000]\n","loss: 0.679764  [51264/60000]\n","loss: 0.630040  [57664/60000]\n","Test Error: \n"," Accuracy: 78.0%, Avg loss: 0.631886 \n","\n","Epoch 3\n","-------------------------------\n","loss: 0.550879  [   64/60000]\n","loss: 0.667174  [ 6464/60000]\n","loss: 0.446437  [12864/60000]\n","loss: 0.660357  [19264/60000]\n","loss: 0.583829  [25664/60000]\n","loss: 0.565582  [32064/60000]\n","loss: 0.603217  [38464/60000]\n","loss: 0.646452  [44864/60000]\n","loss: 0.638313  [51264/60000]\n","loss: 0.537625  [57664/60000]\n","Test Error: \n"," Accuracy: 80.0%, Avg loss: 0.568038 \n","\n","Epoch 4\n","-------------------------------\n","loss: 0.456691  [   64/60000]\n","loss: 0.582707  [ 6464/60000]\n","loss: 0.385027  [12864/60000]\n","loss: 0.590100  [19264/60000]\n","loss: 0.530451  [25664/60000]\n","loss: 0.522050  [32064/60000]\n","loss: 0.549856  [38464/60000]\n","loss: 0.646804  [44864/60000]\n","loss: 0.618940  [51264/60000]\n","loss: 0.473954  [57664/60000]\n","Test Error: \n"," Accuracy: 80.7%, Avg loss: 0.538199 \n","\n","Epoch 5\n","-------------------------------\n","loss: 0.402939  [   64/60000]\n","loss: 0.538840  [ 6464/60000]\n","loss: 0.351413  [12864/60000]\n","loss: 0.545019  [19264/60000]\n","loss: 0.489449  [25664/60000]\n","loss: 0.492423  [32064/60000]\n","loss: 0.519503  [38464/60000]\n","loss: 0.644437  [44864/60000]\n","loss: 0.599365  [51264/60000]\n","loss: 0.437290  [57664/60000]\n","Test Error: \n"," Accuracy: 81.2%, Avg loss: 0.518799 \n","\n","Epoch 6\n","-------------------------------\n","loss: 0.364003  [   64/60000]\n","loss: 0.513277  [ 6464/60000]\n","loss: 0.328813  [12864/60000]\n","loss: 0.515781  [19264/60000]\n","loss: 0.461652  [25664/60000]\n","loss: 0.471845  [32064/60000]\n","loss: 0.496646  [38464/60000]\n","loss: 0.632689  [44864/60000]\n","loss: 0.581813  [51264/60000]\n","loss: 0.418756  [57664/60000]\n","Test Error: \n"," Accuracy: 81.7%, Avg loss: 0.504520 \n","\n","Epoch 7\n","-------------------------------\n","loss: 0.334816  [   64/60000]\n","loss: 0.494545  [ 6464/60000]\n","loss: 0.311507  [12864/60000]\n","loss: 0.497056  [19264/60000]\n","loss: 0.441500  [25664/60000]\n","loss: 0.457449  [32064/60000]\n","loss: 0.477570  [38464/60000]\n","loss: 0.616457  [44864/60000]\n","loss: 0.568043  [51264/60000]\n","loss: 0.409072  [57664/60000]\n","Test Error: \n"," Accuracy: 82.1%, Avg loss: 0.492712 \n","\n","Epoch 8\n","-------------------------------\n","loss: 0.312763  [   64/60000]\n","loss: 0.478934  [ 6464/60000]\n","loss: 0.297895  [12864/60000]\n","loss: 0.481957  [19264/60000]\n","loss: 0.423332  [25664/60000]\n","loss: 0.446537  [32064/60000]\n","loss: 0.461914  [38464/60000]\n","loss: 0.600880  [44864/60000]\n","loss: 0.555767  [51264/60000]\n","loss: 0.403992  [57664/60000]\n","Test Error: \n"," Accuracy: 82.5%, Avg loss: 0.482285 \n","\n","Epoch 9\n","-------------------------------\n","loss: 0.295879  [   64/60000]\n","loss: 0.465108  [ 6464/60000]\n","loss: 0.286453  [12864/60000]\n","loss: 0.470818  [19264/60000]\n","loss: 0.407890  [25664/60000]\n","loss: 0.437861  [32064/60000]\n","loss: 0.448779  [38464/60000]\n","loss: 0.585737  [44864/60000]\n","loss: 0.544381  [51264/60000]\n","loss: 0.400983  [57664/60000]\n","Test Error: \n"," Accuracy: 82.9%, Avg loss: 0.472810 \n","\n","Epoch 10\n","-------------------------------\n","loss: 0.283121  [   64/60000]\n","loss: 0.451965  [ 6464/60000]\n","loss: 0.277195  [12864/60000]\n","loss: 0.460624  [19264/60000]\n","loss: 0.394737  [25664/60000]\n","loss: 0.428960  [32064/60000]\n","loss: 0.437668  [38464/60000]\n","loss: 0.572531  [44864/60000]\n","loss: 0.533909  [51264/60000]\n","loss: 0.398845  [57664/60000]\n","Test Error: \n"," Accuracy: 83.2%, Avg loss: 0.463552 \n","\n","Epoch 11\n","-------------------------------\n","loss: 0.272462  [   64/60000]\n","loss: 0.440941  [ 6464/60000]\n","loss: 0.268433  [12864/60000]\n","loss: 0.450535  [19264/60000]\n","loss: 0.381769  [25664/60000]\n","loss: 0.420876  [32064/60000]\n","loss: 0.427611  [38464/60000]\n","loss: 0.560010  [44864/60000]\n","loss: 0.524717  [51264/60000]\n","loss: 0.396269  [57664/60000]\n","Test Error: \n"," Accuracy: 83.5%, Avg loss: 0.454531 \n","\n","Epoch 12\n","-------------------------------\n","loss: 0.262818  [   64/60000]\n","loss: 0.430731  [ 6464/60000]\n","loss: 0.261873  [12864/60000]\n","loss: 0.440716  [19264/60000]\n","loss: 0.371520  [25664/60000]\n","loss: 0.413487  [32064/60000]\n","loss: 0.419212  [38464/60000]\n","loss: 0.548100  [44864/60000]\n","loss: 0.517137  [51264/60000]\n","loss: 0.394084  [57664/60000]\n","Test Error: \n"," Accuracy: 83.9%, Avg loss: 0.446598 \n","\n","Epoch 13\n","-------------------------------\n","loss: 0.255863  [   64/60000]\n","loss: 0.421292  [ 6464/60000]\n","loss: 0.255766  [12864/60000]\n","loss: 0.432405  [19264/60000]\n","loss: 0.361277  [25664/60000]\n","loss: 0.405994  [32064/60000]\n","loss: 0.410576  [38464/60000]\n","loss: 0.537088  [44864/60000]\n","loss: 0.508293  [51264/60000]\n","loss: 0.391327  [57664/60000]\n","Test Error: \n"," Accuracy: 84.2%, Avg loss: 0.439298 \n","\n","Epoch 14\n","-------------------------------\n","loss: 0.250130  [   64/60000]\n","loss: 0.412371  [ 6464/60000]\n","loss: 0.250646  [12864/60000]\n","loss: 0.424129  [19264/60000]\n","loss: 0.351987  [25664/60000]\n","loss: 0.398840  [32064/60000]\n","loss: 0.403439  [38464/60000]\n","loss: 0.527883  [44864/60000]\n","loss: 0.500008  [51264/60000]\n","loss: 0.388995  [57664/60000]\n","Test Error: \n"," Accuracy: 84.4%, Avg loss: 0.432449 \n","\n","Epoch 15\n","-------------------------------\n","loss: 0.245053  [   64/60000]\n","loss: 0.404938  [ 6464/60000]\n","loss: 0.246263  [12864/60000]\n","loss: 0.415626  [19264/60000]\n","loss: 0.344697  [25664/60000]\n","loss: 0.392705  [32064/60000]\n","loss: 0.396660  [38464/60000]\n","loss: 0.517265  [44864/60000]\n","loss: 0.493128  [51264/60000]\n","loss: 0.386430  [57664/60000]\n","Test Error: \n"," Accuracy: 84.8%, Avg loss: 0.425827 \n","\n","Epoch 16\n","-------------------------------\n","loss: 0.240086  [   64/60000]\n","loss: 0.397919  [ 6464/60000]\n","loss: 0.242414  [12864/60000]\n","loss: 0.407395  [19264/60000]\n","loss: 0.338618  [25664/60000]\n","loss: 0.386410  [32064/60000]\n","loss: 0.389748  [38464/60000]\n","loss: 0.507279  [44864/60000]\n","loss: 0.484280  [51264/60000]\n","loss: 0.384989  [57664/60000]\n","Test Error: \n"," Accuracy: 85.1%, Avg loss: 0.419942 \n","\n","Epoch 17\n","-------------------------------\n","loss: 0.235442  [   64/60000]\n","loss: 0.391944  [ 6464/60000]\n","loss: 0.238278  [12864/60000]\n","loss: 0.399218  [19264/60000]\n","loss: 0.333848  [25664/60000]\n","loss: 0.380855  [32064/60000]\n","loss: 0.385009  [38464/60000]\n","loss: 0.498000  [44864/60000]\n","loss: 0.476762  [51264/60000]\n","loss: 0.384074  [57664/60000]\n","Test Error: \n"," Accuracy: 85.2%, Avg loss: 0.414318 \n","\n","Epoch 18\n","-------------------------------\n","loss: 0.231366  [   64/60000]\n","loss: 0.386859  [ 6464/60000]\n","loss: 0.234834  [12864/60000]\n","loss: 0.392858  [19264/60000]\n","loss: 0.329091  [25664/60000]\n","loss: 0.374490  [32064/60000]\n","loss: 0.379518  [38464/60000]\n","loss: 0.488382  [44864/60000]\n","loss: 0.468809  [51264/60000]\n","loss: 0.381977  [57664/60000]\n","Test Error: \n"," Accuracy: 85.4%, Avg loss: 0.409112 \n","\n","Epoch 19\n","-------------------------------\n","loss: 0.227418  [   64/60000]\n","loss: 0.381471  [ 6464/60000]\n","loss: 0.231247  [12864/60000]\n","loss: 0.385996  [19264/60000]\n","loss: 0.324744  [25664/60000]\n","loss: 0.368508  [32064/60000]\n","loss: 0.375816  [38464/60000]\n","loss: 0.479949  [44864/60000]\n","loss: 0.461190  [51264/60000]\n","loss: 0.380469  [57664/60000]\n","Test Error: \n"," Accuracy: 85.5%, Avg loss: 0.404251 \n","\n","Epoch 20\n","-------------------------------\n","loss: 0.223497  [   64/60000]\n","loss: 0.377189  [ 6464/60000]\n","loss: 0.228555  [12864/60000]\n","loss: 0.379297  [19264/60000]\n","loss: 0.321724  [25664/60000]\n","loss: 0.363354  [32064/60000]\n","loss: 0.372239  [38464/60000]\n","loss: 0.471867  [44864/60000]\n","loss: 0.453145  [51264/60000]\n","loss: 0.378092  [57664/60000]\n","Test Error: \n"," Accuracy: 85.7%, Avg loss: 0.399647 \n","\n","Epoch 21\n","-------------------------------\n","loss: 0.220260  [   64/60000]\n","loss: 0.372773  [ 6464/60000]\n","loss: 0.225616  [12864/60000]\n","loss: 0.373065  [19264/60000]\n","loss: 0.318291  [25664/60000]\n","loss: 0.358467  [32064/60000]\n","loss: 0.368198  [38464/60000]\n","loss: 0.463658  [44864/60000]\n","loss: 0.444726  [51264/60000]\n","loss: 0.377181  [57664/60000]\n","Test Error: \n"," Accuracy: 85.8%, Avg loss: 0.395458 \n","\n","Epoch 22\n","-------------------------------\n","loss: 0.217496  [   64/60000]\n","loss: 0.367795  [ 6464/60000]\n","loss: 0.222970  [12864/60000]\n","loss: 0.366446  [19264/60000]\n","loss: 0.316576  [25664/60000]\n","loss: 0.354071  [32064/60000]\n","loss: 0.365013  [38464/60000]\n","loss: 0.455430  [44864/60000]\n","loss: 0.437555  [51264/60000]\n","loss: 0.375345  [57664/60000]\n","Test Error: \n"," Accuracy: 86.0%, Avg loss: 0.391332 \n","\n","Epoch 23\n","-------------------------------\n","loss: 0.214133  [   64/60000]\n","loss: 0.363328  [ 6464/60000]\n","loss: 0.220315  [12864/60000]\n","loss: 0.360069  [19264/60000]\n","loss: 0.313472  [25664/60000]\n","loss: 0.349851  [32064/60000]\n","loss: 0.360535  [38464/60000]\n","loss: 0.448266  [44864/60000]\n","loss: 0.431387  [51264/60000]\n","loss: 0.373549  [57664/60000]\n","Test Error: \n"," Accuracy: 86.1%, Avg loss: 0.387940 \n","\n","Epoch 24\n","-------------------------------\n","loss: 0.211744  [   64/60000]\n","loss: 0.359389  [ 6464/60000]\n","loss: 0.217888  [12864/60000]\n","loss: 0.354543  [19264/60000]\n","loss: 0.311635  [25664/60000]\n","loss: 0.345395  [32064/60000]\n","loss: 0.356518  [38464/60000]\n","loss: 0.441745  [44864/60000]\n","loss: 0.423539  [51264/60000]\n","loss: 0.371517  [57664/60000]\n","Test Error: \n"," Accuracy: 86.2%, Avg loss: 0.384757 \n","\n","Epoch 25\n","-------------------------------\n","loss: 0.208982  [   64/60000]\n","loss: 0.355804  [ 6464/60000]\n","loss: 0.213115  [12864/60000]\n","loss: 0.347575  [19264/60000]\n","loss: 0.309200  [25664/60000]\n","loss: 0.340377  [32064/60000]\n","loss: 0.353841  [38464/60000]\n","loss: 0.433322  [44864/60000]\n","loss: 0.416715  [51264/60000]\n","loss: 0.369686  [57664/60000]\n","Test Error: \n"," Accuracy: 86.3%, Avg loss: 0.381413 \n","\n","Epoch 26\n","-------------------------------\n","loss: 0.206125  [   64/60000]\n","loss: 0.352226  [ 6464/60000]\n","loss: 0.210594  [12864/60000]\n","loss: 0.340110  [19264/60000]\n","loss: 0.308485  [25664/60000]\n","loss: 0.335761  [32064/60000]\n","loss: 0.350354  [38464/60000]\n","loss: 0.427871  [44864/60000]\n","loss: 0.409827  [51264/60000]\n","loss: 0.366451  [57664/60000]\n","Test Error: \n"," Accuracy: 86.4%, Avg loss: 0.378455 \n","\n","Epoch 27\n","-------------------------------\n","loss: 0.204598  [   64/60000]\n","loss: 0.347436  [ 6464/60000]\n","loss: 0.207484  [12864/60000]\n","loss: 0.333331  [19264/60000]\n","loss: 0.306282  [25664/60000]\n","loss: 0.331542  [32064/60000]\n","loss: 0.346559  [38464/60000]\n","loss: 0.419062  [44864/60000]\n","loss: 0.402908  [51264/60000]\n","loss: 0.363948  [57664/60000]\n","Test Error: \n"," Accuracy: 86.4%, Avg loss: 0.375509 \n","\n","Epoch 28\n","-------------------------------\n","loss: 0.202519  [   64/60000]\n","loss: 0.342570  [ 6464/60000]\n","loss: 0.205299  [12864/60000]\n","loss: 0.327648  [19264/60000]\n","loss: 0.303422  [25664/60000]\n","loss: 0.329060  [32064/60000]\n","loss: 0.343079  [38464/60000]\n","loss: 0.412620  [44864/60000]\n","loss: 0.395895  [51264/60000]\n","loss: 0.360549  [57664/60000]\n","Test Error: \n"," Accuracy: 86.5%, Avg loss: 0.372738 \n","\n","Epoch 29\n","-------------------------------\n","loss: 0.200891  [   64/60000]\n","loss: 0.340078  [ 6464/60000]\n","loss: 0.202991  [12864/60000]\n","loss: 0.321562  [19264/60000]\n","loss: 0.300564  [25664/60000]\n","loss: 0.325359  [32064/60000]\n","loss: 0.339250  [38464/60000]\n","loss: 0.405276  [44864/60000]\n","loss: 0.390105  [51264/60000]\n","loss: 0.358217  [57664/60000]\n","Test Error: \n"," Accuracy: 86.6%, Avg loss: 0.370006 \n","\n","Epoch 30\n","-------------------------------\n","loss: 0.199533  [   64/60000]\n","loss: 0.337489  [ 6464/60000]\n","loss: 0.200870  [12864/60000]\n","loss: 0.316883  [19264/60000]\n","loss: 0.299368  [25664/60000]\n","loss: 0.323305  [32064/60000]\n","loss: 0.335058  [38464/60000]\n","loss: 0.397564  [44864/60000]\n","loss: 0.385468  [51264/60000]\n","loss: 0.355186  [57664/60000]\n","Test Error: \n"," Accuracy: 86.7%, Avg loss: 0.367630 \n","\n","Epoch 31\n","-------------------------------\n","loss: 0.197352  [   64/60000]\n","loss: 0.336073  [ 6464/60000]\n","loss: 0.198679  [12864/60000]\n","loss: 0.311431  [19264/60000]\n","loss: 0.297987  [25664/60000]\n","loss: 0.320017  [32064/60000]\n","loss: 0.330846  [38464/60000]\n","loss: 0.391660  [44864/60000]\n","loss: 0.380254  [51264/60000]\n","loss: 0.351871  [57664/60000]\n","Test Error: \n"," Accuracy: 86.8%, Avg loss: 0.365152 \n","\n","Epoch 32\n","-------------------------------\n","loss: 0.195207  [   64/60000]\n","loss: 0.332390  [ 6464/60000]\n","loss: 0.196892  [12864/60000]\n","loss: 0.306106  [19264/60000]\n","loss: 0.296783  [25664/60000]\n","loss: 0.318515  [32064/60000]\n","loss: 0.328092  [38464/60000]\n","loss: 0.384877  [44864/60000]\n","loss: 0.373290  [51264/60000]\n","loss: 0.351002  [57664/60000]\n","Test Error: \n"," Accuracy: 86.9%, Avg loss: 0.362950 \n","\n","完成!\n"]}],"source":["def train_loop(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset) # 获取数据集中样本的总数\n","    model.train() # 将模型设置为训练模式，非必需\n","    for batch, (X, y) in enumerate(dataloader): # enumerate是一个Python内置函数，它会返回一个包含索引和值的迭代器\n","        # 计算预测值和损失\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","        # 反向传播\n","        loss.backward()\n","        optimizer.step() # 通过优化算法更新模型的参数。\n","\n","        # 在PyTorch中，每次进行反向传播时，计算的梯度会默认累积在模型的参数中。为了避免梯度累加，通常在每次迭代前，需要将梯度清零\n","        optimizer.zero_grad() # 清除所有模型参数的梯度。\n","\n","        if batch % 100 == 0:\n","            # current获取进度位置\n","            loss, current = loss.item(), batch * batch_size + len(X) # loss.item()会返回当前批次的损失值，便于打印和记录\n","            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\") # 格式化字符串\n","\n","def test_loop(dataloader, model, loss_fn):\n","    size = len(dataloader.dataset) # 非必要\n","    num_batches = len(dataloader)\n","    test_loss, correct = 0, 0 # 初始化\n","\n","    # 在测试模式下不使用梯度\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            pred = model(X)\n","            # item()将单个元素的张量转换为标量\n","            test_loss += loss_fn(pred, y).item() # 当前批次的损失累加到test_loss变量，便于后续计算平均损失\n","\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","            # argmax(1)会返回在每个样本中，预测分数最大的类别的索引（即预测的类别）\n","            # (pred.argmax(1) == y): 这个表达式会产生一个布尔张量，表示每个样本的预测标签是否与真实标签y相等。若预测正确，结果为True，否则为False\n","            # .type(torch.float):将布尔张量转换为浮点数张量，其中True转换为1.0，False转换为0.0\n","            # .sum():对转换后的浮点数张量求和，最终的和就是当前批次中预测正确的样本数量\n","\n","    test_loss /= num_batches # 计算平均损失，num_batches：表示测试数据集被分成的批次数量\n","    correct /= size # 计算准确率，size是测试集的总样本数\n","\n","    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\") # 字符串格式化\n","\n","loss_fn = nn.CrossEntropyLoss() # 损失函数\n","learning_rate = 0.01 # 学习率\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # 优化器\n","batch_size = train_dataloader.batch_size # 批次大小\n","epochs = 32 # 训练轮数\n","for t in range(epochs):\n","    print(f\"Epoch {t+1}\\n-------------------------------\")\n","    train_loop(train_dataloader, model, loss_fn, optimizer)\n","    test_loop(test_dataloader, model, loss_fn)\n","print(\"完成!\")"]},{"cell_type":"markdown","source":["## 六，保存并加载模型"],"metadata":{"id":"OG3VZgP7pWGG"}},{"cell_type":"markdown","source":["### 1，保存和加载模型权重"],"metadata":{"id":"Q27Jqi6wpdYf"}},{"cell_type":"code","source":["import torch\n","import torchvision.models as models # 通过models子模块导入了torchvision中的所有模型。使用models作为别名\n","\n","model = models.vgg16(weights='IMAGENET1K_V1') # 加载一个预训练的VGG16模型并加载在ImageNet数据集上预训练的权重\n","\n","# 将PyTorch对象（如张量、模型的 state_dict）保存到文件model_weights.pth中\n","torch.save(model.state_dict(), 'model_weights.pth') # state_dict()是PyTorch中每个模型的一个方法，用来获取模型的状态字典（即权重和偏置）\n","\n","# 要加载模型权重，需要先创建相同模型的实例，然后使用load_state_dict()方法加载参数。\n","model = models.vgg16()\n","model.load_state_dict(torch.load('model_weights.pth', weights_only=True)) # weights_only=True是在torch.load中传递的一个额外参数，用来指示仅加载模型的权重\n","model.eval() # model.eval()：这行代码将模型设置为评估模式"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YCq077bapuk2","executionInfo":{"status":"ok","timestamp":1731571368764,"user_tz":-480,"elapsed":13659,"user":{"displayName":"YANGSHEN YU","userId":"05751253873803936475"}},"outputId":"5804d6ac-4518-495f-f76f-e2637b0c1fc7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n","100%|██████████| 528M/528M [00:06<00:00, 79.6MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["### 2， 保存和加载带有形状的模型"],"metadata":{"id":"_RI-rECQreNK"}},{"cell_type":"code","source":["# 我们可能希望将此类的结构与模型一起保存，在这种情况下，我们可以将model（而不是model.state_dict()）传递给保存函数\n","torch.save(model, 'model.pth') # 保存整个模型\n","model = torch.load('model.pth') # 加载整个模型"],"metadata":{"id":"yz2lFAe5s48T"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true,"mount_file_id":"1qGC6nkMy6otivEH2A_ErCp3obpQNqRhM","authorship_tag":"ABX9TyNLoInkxoWeMRUi6mu4rMkf"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}