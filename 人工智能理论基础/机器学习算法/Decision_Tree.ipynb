{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNs+D9FylnG3wdu5cqGKX7J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["决策树算法"],"metadata":{"id":"On23CiiuYQHb"}},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O6lTJNtwYLTz","executionInfo":{"status":"ok","timestamp":1729145160492,"user_tz":-480,"elapsed":516,"user":{"displayName":"YANGSHEN YU","userId":"05751253873803936475"}},"outputId":"659b69c5-8b14-42bd-e864-48611d6d7a28"},"outputs":[{"output_type":"stream","name":"stdout","text":["预测结果: [1, 1, 1, 1, 1, 0, 0, 1, 1, 0]\n"]}],"source":["import numpy as np\n","\n","class DecisionTree:\n","    # 计算熵\n","    def entropy(self, y):\n","        if len(y) == 0: # 如果没有样本，熵为0\n","            return 0\n","\n","        class_counts = np.bincount(y) # 统计每个类别的样本数\n","        probabilities = class_counts / len(y) # 计算各类的概率\n","\n","        return -np.sum(probabilities * np.log2(probabilities + 1e-9)) # 1e-9:小数，防止出现对0取对数\n","\n","    # 计算信息增益\n","    def information_gain(self, y, left_indices, right_indices):\n","        parent_entropy = self.entropy(y)  # 计算父节点的熵\n","\n","        # 如果某一侧没有样本，则信息增益为0\n","        if len(y[left_indices]) == 0 or len(y[right_indices]) == 0:\n","            return 0\n","\n","        n = len(y)  # 总样本数\n","        n_left = len(y[left_indices])  # 左侧样本数\n","        n_right = len(y[right_indices])  # 右侧样本数\n","\n","        # 计算子节点的熵\n","        child_entropy = (\n","            (n_left / n) * self.entropy(y[left_indices]) +\n","            (n_right / n) * self.entropy(y[right_indices])\n","        )\n","\n","        # 信息增益为父节点熵减去子节点熵\n","        return parent_entropy - child_entropy\n","\n","    # 决策树设置\n","    def __init__(self, min_samples_split=2, max_depth=None):\n","        self.min_samples_split = min_samples_split  # 最小样本分裂数\n","        self.max_depth = max_depth  # 最大深度\n","        self.tree = None  # 对决策树根节点进行初始化\n","\n","    # 拟合模型\n","    def fit(self, X, y):\n","        self.tree = self.build_tree(X, y)\n","\n","    # 创建决策树\n","    def build_tree(self, X, y, depth=0):\n","        # 创建树的节点\n","        num_samples, num_features = X.shape # num_samples表示样本的数量，num_features表示特征的数量\n","        unique_classes = np.unique(y) # np.unique函数找到标签数组y中所有唯一的类标签，这将返回一个数组\n","\n","        # 如果样本数少于最小分裂数或只有一个类，则返回叶节点\n","        if num_samples < self.min_samples_split or len(unique_classes) == 1:\n","            return self._create_leaf(y)\n","\n","        # 如果达到最大深度，则返回叶节点\n","        if self.max_depth is not None and depth >= self.max_depth:\n","            return self._create_leaf(y)\n","\n","        # 获取最佳特征和分裂点\n","        best_feature, best_threshold = self._best_split(X, y, num_features)\n","\n","        # 如果没有找到合适的分裂点，则返回叶节点\n","        if best_feature is None:\n","            return self._create_leaf(y)\n","\n","        # 根据最佳特征和分裂点进行分裂\n","        left_indices = X[:, best_feature] < best_threshold # X[:, best_feature]：从特征矩阵X中选择当前最佳特征（best_feature）的所有样本。\n","        right_indices = X[:, best_feature] >= best_threshold\n","\n","        left_subtree = self.build_tree(X[left_indices], y[left_indices], depth + 1) # 递归地构建左子树，并将其存储在left_subtree变量中。\n","        right_subtree = self.build_tree(X[right_indices], y[right_indices], depth + 1)\n","\n","        # 返回当前节点的信息\n","        return {\n","            'feature_index': best_feature,\n","            'threshold': best_threshold,\n","            'left': left_subtree,\n","            'right': right_subtree\n","        }\n","\n","    # 寻找最佳特征和分裂点\n","    def _best_split(self, X, y, num_features):\n","        best_gain = -1  # 初始化最佳增益\n","        best_feature = None\n","        best_threshold = None\n","\n","        for feature_index in range(num_features):\n","            unique_classes = np.bincount(y)\n","            thresholds, classes = zip(*sorted(zip(X[:, feature_index], y)))\n","            # 将当前特征的值（X[:, feature_index]）和对应的标签（y）配对，生成一个元组列表。每个元组的形式为(特征值, 标签)。\n","            # sorted(...)：将配对的元组按特征值进行排序，这样有助于找到潜在的分裂点。\n","            # zip(*)：解压排序后的元组列表，将特征值和标签分开。thresholds将包含特征值，classes将包含对应的标签。\n","\n","            num_left = [0] * len(np.unique(y))\n","            num_right = [np.sum(classes == c) for c in unique_classes]\n","\n","            # 初始化一个列表num_left，用于记录左子树中每个类的样本数量。np.unique(y)返回标签的唯一值，因此列表的长度等于类别的数量。初始时，每个类别的样本数量都设置为0。\n","            # 对于num_right生成一个列表，记录每个类出现的次数\n","            for i in range(1, len(classes)):  # 从第一个分裂点开始\n","                class_label = classes[i - 1]\n","                num_left[class_label] += 1\n","                num_right[class_label] -= 1\n","\n","                # 计算当前分裂点的增益\n","                if thresholds[i] == thresholds[i - 1]:\n","                    continue  # 避免重复分裂\n","\n","                gain = self.information_gain(y, num_left, num_right)\n","\n","                if gain > best_gain:\n","                    best_gain = gain\n","                    best_feature = feature_index\n","                    best_threshold = (thresholds[i] + thresholds[i - 1]) / 2  # 取平均作为分裂点\n","\n","            # 检查是否找到有效的分裂\n","            if best_gain > 0:\n","                return best_feature, best_threshold\n","            else:\n","                return None, None  # 返回无效的分裂标志\n","\n","    # 返回出现最多的类作为叶节点\n","    def _create_leaf(self, y):\n","        return np.bincount(y).argmax()  # .argmax()：这个方法返回数组中最大值的索引\n","\n","    # 预测函数\n","    def predict(self, X):\n","        return [self._predict(sample, self.tree) for sample in X]\n","\n","    # 递归预测\n","    def _predict(self, sample, tree):\n","        if isinstance(tree, dict):  # 如果当前节点是字典，表示不是叶节点\n","            feature_index = tree['feature_index']\n","            threshold = tree['threshold']\n","            if sample[feature_index] < threshold:\n","                return self._predict(sample, tree['left'])\n","            else:\n","                return self._predict(sample, tree['right'])\n","        else:  # 如果是叶节点，返回类别\n","            return tree\n","\n","    # 示例使用\n","if __name__ == \"__main__\":\n","    # 示例数据集\n","    X = np.array([[85, 85, 0],\n","                  [80, 70, 1],\n","                  [78, 90, 0],\n","                  [90, 95, 0],\n","                  [95, 60, 1],\n","                  [70, 70, 1],\n","                  [60, 80, 1],\n","                  [82, 80, 0],\n","                  [88, 70, 0],\n","                  [75, 60, 1]])\n","    y = np.array([0, 0, 1, 1, 1, 0, 0, 1, 1, 0])\n","\n","    # 创建并训练决策树\n","    tree = DecisionTree(max_depth=3)\n","    tree.fit(X, y)\n","\n","    # 进行预测\n","    predictions = tree.predict(X)\n","    print(\"预测结果:\", predictions)\n"]}]}